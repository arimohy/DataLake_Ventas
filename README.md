
# Proyecto Final: Data Lake - Apache Spark

Este repositorio contiene el trabajo final del curso de Apache Spark, donde se implementa un Data Lake para el análisis y gestión de datos de ventas. A través de este proyecto, se busca demostrar el conocimiento adquirido en la configuración, procesamiento y análisis de datos utilizando Apache Spark.

## Contenido del Repositorio

- **`ProyectoFinal-DataLake-YhomiraAlexandraYupayccanaLopa.dbc`:** Archivo en formato Databricks que contiene las implementaciones realizadas durante el proyecto.
- **`ProyectoFinal-DataLake-YhomiraAlexandraYupayccanaLopa.html`:** Versión exportada del notebook en formato HTML, ideal para una vista rápida del análisis y resultados.
- **`ProyectoFinal-DataLake-YhomiraAlexandraYupayccanaLopa.ipynb`:** Notebook en formato Jupyter con el desarrollo completo del proyecto, que incluye código, comentarios y visualizaciones.
- **`ProyectoFinal-DataLake-YhomiraAlexandraYupayccanaLopa.py`:** Archivo en formato Python generado a partir del notebook para una ejecución más flexible y modular.
- **`README.md`:** Este archivo, que describe el proyecto y su contenido.

## Descripción del Proyecto

El proyecto tiene como objetivo construir un Data Lake utilizando Apache Spark para analizar datos de ventas de manera eficiente y escalable. Durante el desarrollo, se llevaron a cabo las siguientes actividades:

1. Procesamiento y transformación de datos en Apache Spark.
2. Uso de la arquitectura medallon y sus respectivas capas

## Visualización del Notebook

Para visualizar directamente el notebook, puedes acceder al archivo en GitHub o abrirlo en [nbviewer](https://nbviewer.org/):
- [Notebook en formato `.ipynb`](https://github.com/arimohy/DataLake_Ventas/blob/main/ProyectoFinal-DataLake-YhomiraAlexandraYupayccanaLopa.ipynb)

## Cómo Usar Este Repositorio

1. Clona el repositorio en tu máquina local:
   ```bash
   git clone https://github.com/arimohy/DataLake_Ventas.git
   cd DataLake_Ventas
   ```
2. Instala las dependencias necesarias (si aplica).
3. Abre el archivo `.ipynb` en Jupyter Notebook, Google Colab, o cualquier herramienta compatible.

## Tecnologías Utilizadas

- **Apache Spark (pySpark) :** Procesamiento de datos a gran escala.
- **Python:** Lenguaje principal para la implementación.
- **Databricks:** Desarrollo

## Documentación Adicional

- El archivo `.html` ofrece una vista rápida del notebook sin necesidad de herramientas adicionales.
- El archivo `.py` puede ser utilizado para ejecutar las transformaciones directamente en tu entorno Python.

## Contacto

Si tienes alguna pregunta, no dudes en contactarme en [LinkedIn](https://www.linkedin.com/in/yhomiraalexandrayupayccanalopa/).
